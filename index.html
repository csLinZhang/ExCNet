<html>

<head>
<meta http-equiv="Content-Language" content="zh-cn">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>Zero-Shot Restoration of Back-li</title>
<style>
<!--
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
-->
</style>
</head>

<body>

<table class="MsoNormalTable" border="0" cellpadding="0" width="1217" id="table3" height="35">
	<tr>
		<td valign="top" style="width: 1211px; height: 31px; padding: .75pt" align="left">
		<p class="text"><span lang="en-us">
		<font face="Calibri" size="5" color="#0000FF"><b>ExCNet: A Framework for Zero-Shot Restoration 
		of Back-lit Images Using Deep Internal Learning</b></font></span></p>
		<p class="text"><span lang="en-us">
		<font face="Calibri" size="4" color="#0000FF">School of Software 
		Engineering, Tongji University, 
		Shanghai, China</font></span></td>
	</tr>
</table>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Introduction</font></b></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">This is the 
website for our work &quot;Zero-Shot Restoration of Back-lit Images Using Deep 
Internal Learning&quot;.<br>
<br>
How to restore back-lit images still remains a challenging task. 
State-of-the-art methods in this field are based on supervised learning and thus 
they are usually restricted to specific training data. In this paper, we propose 
a &quot;zero-shot&quot; scheme for back-lit image restoration, which exploits the power of 
deep learning, but does not rely on any prior image examples or prior training. 
Specifically, we train a small image-specific CNN, namely ExCNet (short for 
Exposure Correction Network) at test time, to estimate the ``S-curve'' that best 
fits the test back-lit image. Once the S-curve is estimated, the test image can 
be then restored straightforwardly. ExCNet can adapt itself to different 
settings per image. This makes our approach widely applicable to different 
shooting scenes and kinds of back-lighting conditions. Statistical studies 
performed on 1512 real back-lit images demonstrate that our approach can 
outperform the competitors by a large margin. To the best of our knowledge, our 
scheme is the first unsupervised CNN-based back-lit image restoration method. To 
make the results reproducible, the source code is available on this website.</font></span></p>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Source Codes</font></b></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">1.
<a href="ExCNet.ipynb">ExCNet.ipynb</a></font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">This is the 
code of ExCNet, including the network model and the back-lit images restoration 
procedure. The prerequisites for running the .ipynb file is the Tensorflow 
environment and Jupyter Notebook.</font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">2.
<a href="https://pan.baidu.com/s/10jOitYhcW4w-0vaeNO7-qw">BacklitImages.zip</a>,
<a href="https://pan.baidu.com/s/1sWs3owxfSnvKXY2zOLsH9w">BacklitVideos.zip</a></font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">These are 
some back-lit images and videos for testing. The extract codes are 'v752' and 'yerr' 
respectively.</font></span></p>
<hr>
<p align="justify"><font face="Calibri">Last update: <span lang="en-us">Aug. 14,
</span>201<span lang="en-us">9</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font></p>

</body>

</html>
