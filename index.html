<html>

<head>
<meta http-equiv="Content-Language" content="zh-cn">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>Zero-Shot Restoration of Back-li</title>
<style>
<!--
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
-->
</style>
</head>

<body>

<table class="MsoNormalTable" border="0" cellpadding="0" width="1217" id="table3" height="35">
	<tr>
		<td valign="top" style="width: 1211px; height: 31px; padding: .75pt" align="left">
		<p class="text"><span lang="en-us">
		<font face="Calibri" size="5" color="#0000FF"><b>ExCNet: A Framework for Zero-Shot Restoration 
		of Back-lit Images Using Deep Internal Learning</b></font></span></p>
		<p class="text"><span lang="en-us">
		<font face="Calibri" size="4" color="#0000FF">School of Software 
		Engineering, Tongji University, 
		Shanghai, China</font></span></td>
	</tr>
</table>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Introduction</font></b></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">This is the 
website for our work &quot;Zero-Shot Restoration of Back-lit Images Using Deep 
Internal Learning&quot;.<br>
<br>
How to restore back-lit images still remains a challenging task. 
State-of-the-art methods in this field are based on supervised learning and thus 
they are usually restricted to specific training data. In this paper, we propose 
a &quot;zero-shot&quot; scheme for back-lit image restoration, which exploits the power of 
deep learning, but does not rely on any prior image examples or prior training. 
Specifically, we train a small image-specific CNN, namely ExCNet (short for 
Exposure Correction Network) at test time, to estimate the ``S-curve'' that best 
fits the test back-lit image. Once the S-curve is estimated, the test image can 
be then restored straightforwardly. ExCNet can adapt itself to different 
settings per image. This makes our approach widely applicable to different 
shooting scenes and kinds of back-lighting conditions. Statistical studies 
performed on 1512 real back-lit images demonstrate that our approach can 
outperform the competitors by a large margin. To the best of our knowledge, our 
scheme is the first unsupervised CNN-based back-lit image restoration method. To 
make the results reproducible, the source code is available on this website.</font></span></p>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Key Ideas of ExCNet</font></b></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">(1) The core 
of our approach is a specially designed CNN, namely ExCNet (Exposure Correction 
Network). Given a test back-lit image </font>
<font style="font-size: 13pt; font-style: italic" face="Times New Roman">I</font><font face="Calibri" style="font-size: 13pt">, 
ExCNet can be trained in an image specific way to estimate the parametric 
&quot;S-curve&quot; that best fits </font>
<font style="font-size: 13pt; font-style: italic" face="Times New Roman">I</font><font face="Calibri" style="font-size: 13pt">. 
S-curve is widely adopted by photo editing softwares as an interactive tool for 
manually correcting ill-exposed images. When S-curve is ready, </font>
<font style="font-size: 13pt" face="Times New Roman"><i>I</i></font><font face="Calibri" style="font-size: 13pt"> 
can be restored straightforwardly. To our knowledge, our work is the first 
unsupervised learning framework to correct image exposure automatically. Our 
image-specific method can be widely applicable to different shooting scenes and 
kinds of lighting conditions.</font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">(2) When 
designing ExCNet, a key issue is how to devise a loss function that can evaluate 
an image's degree of being ill-exposed. To this end, motivated by the 
formulation of MRF (Markov Random Field), we design a block-based loss function, 
which tends to maximize the visibility of all blocks while keeping the relative 
difference between neighboring blocks. </font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">(3) Due to 
the CNN structure of ExCNet, our method could learn the mapping relationship 
between images and their best &quot;S-curve&quot; parameters. Thus along with the 
increasing of processed images, ExCNet takes less iterations to converge to the 
optimized curve when facing an unseen image. Even though it is trained at test 
time, it runs very fast since the network is small and the training usually 
converges after several iterations. Besides, when handling a video stream, the 
correction of subsequent frames could be guided by the parameters of the 
previous frames, which would not lead to significant flickering artifacts and 
have a relatively low computational cost. Compared with typical supervised 
learning based schemes, ExCNet is more suitable to be implemented in a mobile or 
on-chip system.<br>
<br>
<img border="0" src="excnet.png" width="801" height="281"></font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">The structure 
of ExCNet. Each training iteration of ExCNet can be conceptually considered as 
having two stages, adjusting </font>
<font style="font-size: 13pt; font-style: italic" face="Times New Roman">I<sub>l</sub></font><font face="Calibri" style="font-size: 13pt"> 
using the intermediate S-curve and deriving the loss.</font></span></p>
<p><img border="0" src="flowchart.png" width="832" height="347"></p>
<p><font style="font-size: 13pt" face="Calibri">The overall pipeline of back-lit 
image restoration using ExCNet. The restoration pipeline comprises three major 
steps, S-curve estimation, luminance channel restoration, and chrominance 
adjustment.</font></p>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Source Codes</font></b></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">1.
<a href="ExCNet.ipynb">ExCNet.ipynb</a></font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">This is the 
code of ExCNet, including the network model and the back-lit images restoration 
procedure. The prerequisites for running the .ipynb file is the Tensorflow 
environment and Jupyter Notebook.</font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">2.
<a href="https://pan.baidu.com/s/10jOitYhcW4w-0vaeNO7-qw">BacklitImages.zip</a>,
<a href="https://pan.baidu.com/s/1sWs3owxfSnvKXY2zOLsH9w">BacklitVideos.zip</a></font></span></p>
<p><span lang="en-us"><font face="Calibri" style="font-size: 13pt">These are 
some back-lit images and videos for testing. The extract codes are 'v752' and 'yerr' 
respectively.</font></span></p>
<hr>
<p align="justify"><font face="Calibri">Last update: <span lang="en-us">Sep. 11,
</span>201<span lang="en-us">9</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font></p>

</body>

</html>
